////////////////////////////////////////////////////////////////////////////////
// Copyright (c) 2014-2021, Lawrence Livermore National Security, LLC.
// Produced at the Lawrence Livermore National Laboratory.
// Written by the LBANN Research Team (B. Van Essen, et al.) listed in
// the CONTRIBUTORS file. <lbann-dev@llnl.gov>
//
// LLNL-CODE-697807.
// All rights reserved.
//
// This file is part of LBANN: Livermore Big Artificial Neural Network
// Toolkit. For details, see http://software.llnl.gov/LBANN or
// https://github.com/LLNL/LBANN.
//
// Licensed under the Apache License, Version 2.0 (the "Licensee"); you
// may not use this file except in compliance with the License.  You may
// obtain a copy of the License at:
//
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
// implied. See the License for the specific language governing
// permissions and limitations under the license.
////////////////////////////////////////////////////////////////////////////////

syntax = "proto3";

package lbann_data;

import "google/protobuf/wrappers.proto";

import "datatype.proto";
import "operators.proto";

// Lives here because it's used by both Convolution and
// Deconvolution.
enum ConvTensorOpsMode {
  // Use the global default.
  DEFAULT_TENSOR_OPS = 0;
  // Explicitly disable tensor ops.
  NO_TENSOR_OPS = 1;
  // Use tensor ops -- allows conversion FP32->FP16
  USE_TENSOR_OPS = 2;
}

/** @brief Neural network tensor operation
 *
 *  Layers in a neural network are arranged as a directed acyclic
 *  graph. They take one input tensor from each parent layer and send
 *  an output tensor to each child layer. Some layers may recieve
 *  tensors from weights objects (trainable parameters).
 *
 *  LBANN performs implicit mini-batching. If the user specifies a
 *  layer to handle 3D image data (in channel-height-width format), it
 *  is stored internally as a 4D tensor (in NCHW format).
 *
 *  The default value for fields in protobuf messages is zero-like
 *  (false for bool, empty string for string). Thus, all defaults are
 *  zero-like unless otherwise stated.
 */
message Layer {

  // ===========================================
  // Basic layer options
  // ===========================================

  /** @brief Unique identifier for layer
   *  @details Must not contain spaces.
   */
  string name = 50;

  /** @brief Parent layers
   *  @details Space-separated list of layer names
   */
  string parents = 151;
  /** @brief Child layers
   *  @details Space-separated list of layer names
   */
  string children = 152;
  /** @brief Weights objects
   *
   *  Space-separated list of weights names. Weights are typically
   *  used as trainable parameters.
   */
  string weights = 54;

  /** @brief Data tensor device
   *
   *  If LBANN has been built with GPU support, default is GPU.
   *  Otherwise, CPU.
   *
   *  Options: CPU or GPU
   */
  string device_allocation = 55;
  /** @brief Data tensors datatype */
  DataType datatype = 57;

  // ===========================================
  // Advanced options
  // ===========================================

  /** @brief Hint layer for configuration
   *
   *  Advanced option for configuring certain layers. Typically used
   *  to specify that a layer has the same output dimensions as
   *  another.
   */
  string hint_layer = 56;
  /** @brief Data tensor layout
   *  @details Options: data_parallel (default) or model_parallel
   */
  string data_layout = 52;
  /** @brief Configuration for advanced parallelization strategies */
  ParallelStrategy parallel_strategy = 58;

  // ===========================================
  // Deprecated options
  // ===========================================

  /// Deprecated
  bool num_neurons_from_data_reader = 53;
  /// Deprecated
  bool freeze = 5;
  /// Deprecated
  repeated WeightsData weights_data = 153;
  /// Deprecated
  string top = 154;
  /// Deprecated
  string bottom = 155;
  /// Deprecated
  string type = 156;

  // ===========================================
  // Concrete layer types
  // ===========================================
  // Note: This is a somewhat hacky implementation of class
  // inheritance.

  oneof layer_type {

    // Input layers
    Input input = 2;

    // Operator layers
    OperatorLayer operator_layer = 701; // Name chosen to avoid collision

    // Transform layers
    Reshape reshape = 306;
    Pooling pooling = 12;
    Concatenation concatenation = 300;
    Slice slice = 301;
    Split split = 302;
    Sum sum = 303;
    Cross_Grid_Sum_Slice cross_grid_sum_slice = 338;
    Cross_Grid_Sum cross_grid_sum = 339;
    WeightedSum weighted_sum = 323;
    Unpooling unpooling = 304;
    Hadamard hadamard = 308;
    Constant constant = 309;
    Reduction reduction = 310;
    Evaluation evaluation = 311;
    Gaussian gaussian = 312;
    Bernoulli bernoulli = 313;
    Uniform uniform = 314;
    Crop crop = 316;
    CategoricalRandom categorical_random = 317;
    DiscreteRandom discrete_random = 318;
    Dummy dummy = 319;
    StopGradient stop_gradient = 320;
    InTopK in_top_k = 324;
    Sort sort = 325;
    WeightsLayer weights_layer = 326;
    Tessellate tessellate = 327;
    Scatter scatter = 334;
    Gather gather = 335;
    BatchwiseReduceSum batchwise_reduce_sum = 336;

    // Learning layers
    FullyConnected fully_connected = 11;
    Convolution convolution = 13;
    Deconvolution deconvolution = 305;
    Embedding embedding = 328;
    ChannelwiseScaleBias channelwise_scale_bias = 329;
    EntrywiseScaleBias entrywise_scale_bias = 330;
    ChannelwiseFullyConnected channelwise_fully_connected = 331;
    GRU gru = 333;

    // Loss layers
    CrossEntropy cross_entropy = 60;
    MeanSquaredError mean_squared_error = 61;
    MeanAbsoluteError mean_absolute_error = 62;
    CategoricalAccuracy categorical_accuracy = 63;
    TopKCategoricalAccuracy top_k_categorical_accuracy = 64;
    L2Norm2 l2_norm2 = 65;
    L1Norm l1_norm = 66;

    // Math layers
    MatMul matmul = 470;
    DFTAbs dft_abs = 471;

    // Regularization layers
    BatchNormalization batch_normalization = 19;
    LocalResponseNormalization local_response_normalization = 20;
    Dropout dropout = 21;
    SeluDropout selu_dropout = 229;
    EntrywiseBatchNormalization entrywise_batch_normalization = 230;
    LayerNorm layer_norm = 231;
    InstanceNorm instance_norm = 232;

    // Activation layers
    Elu elu = 200;
    Identity identity = 201;
    LeakyRelu leaky_relu = 202;
    LogSoftmax log_softmax = 204;
    Relu relu = 205;
    Softmax softmax = 208;

    // Image layers
    BilinearResize bilinear_resize = 500;
    Rotation rotation = 501;
    CompositeImageTransformation composite_image_transformation = 502;

    // Miscellaneous layers
    Covariance covariance = 600;
    Variance variance = 601;
    ChannelwiseMean channelwise_mean = 602;
    MiniBatchIndex mini_batch_index = 603;
    MiniBatchSize mini_batch_size = 604;
    Argmax argmax = 605;
    Argmin argmin = 606;
    OneHot one_hot = 607;
    ChannelwiseSoftmax channelwise_softmax = 608;
    DistEmbedding dist_embedding = 609;
    UniformHash uniform_hash = 610;
    RowwiseWeightsNorms rowwise_weights_norms = 611;

  }

  // ---------------------------
  // Operator layers
  // ---------------------------

  /** @brief Layer composed of one or more operator objects
   *
   *  Operators are applied sequentially.
   */
  message OperatorLayer {
    repeated Operator ops = 1;
  }

  // ---------------------------
  // Math layers
  // ---------------------------

  /** @brief Absolute value of discrete Fourier transform
   *
   *  One-, two-, or three-dimensional data is allowed.
   *
   *  The implementation is meant to be as flexible as possible. We
   *  use FFTW for the CPU implementation; whichever types your
   *  implementation of FFTW supports will be supported in this layer
   *  at runtime. The GPU implementation uses cuFFT on NVIDIA GPUs and
   *  will support float and double at runtime (assuming CUDA support
   *  is enabled). A future implementation will support rocFFT for AMD
   *  GPUs.
   *
   *  Currently, LBANN only supports outputting the same type that is
   *  used as input. As such, in forward propagation, this will do a
   *  DFT and then compute the absolute value of the output
   *  implicitly. The intention is to support immediate customer need
   *  now; we will generalize this as LBANN learns to support
   *  different input/output data types.
   */
  message DFTAbs {}

  /** @brief Matrix multiplication.
   *
   *  Performs matrix product of two 2D input tensors. If the input
   *  tensors are 3D, then matrix products are computed independently
   *  over the first dimension, in a similar manner as NumPy's matmul
   *  function.
   */
  message MatMul {
    /// Whether to transpose matrices from first input tensor
    bool transpose_a = 1;
    /// Whether to transpose matrices from second input tensor
    bool transpose_b = 2;
  }

  // ---------------------------
  // Activation layers
  // ---------------------------

  /** @brief Exponential linear unit
   *
   *  @f[
   *    \text{ELU}(x; \alpha) =
   *      \begin{cases}
   *        x                & x > 0 \\
   *        \alpha (e^x - 1) & x \leq 0
   *      \end{cases}
   *  @f]
   *  @f$\alpha@f$ should be non-negative. See:
   *
   *  Djork-Arne Clevert, Thomas Unterthiner, and Sepp Hochreiter.
   *  "Fast and accurate deep network learning by exponential linear
   *  units (ELUs)." arXiv preprint arXiv:1511.07289 (2015).
   */
  message Elu {
    /// Default: 1. Should be >=0.
    double alpha = 1;
  }
  /** @brief Output the input tensor
   *
   *  This layer is very cheap since it just involves setting up
   *  tensor views.
   */
  message Identity {}

  /**
   *  @f[
   *    \text{LeakyReLU}(x; \alpha) =
   *      \begin{cases}
   *        x        & x > 0 \\
   *        \alpha x & x \leq 0
   *      \end{cases}
   *  @f]
   *  See:
   *
   *  Andrew L. Maas, Awni Y. Hannun, and Andrew Y. Ng. "Rectifier
   *  nonlinearities improve neural network acoustic models." In
   *  Proc. ICML, vol. 30, no. 1, p. 3. 2013.
   */
  message LeakyRelu {
    /// Default: 0.01
    double negative_slope = 1;
  }

  /** @brief Logarithm of softmax function
   *
   *  @f[ \log \text{softmax}(x)_i = x_i - \log \sum_j e^{x_j} @f]
   */
  message LogSoftmax {}

  /** @brief Rectified linear unit
   *
   *  \f[ ReLU(x) = \text{max}(x, 0) \f]
   */
  message Relu {}

  /**
   *  @f[ \text{softmax}(x)_i = \frac{e^{x_i}}{\sum_j e^{x_j}} @f]
   */
  message Softmax {
    /// Options: instance (default), channel
    string softmax_mode = 1;
  }

  // ---------------------------
  // Loss layers
  // ---------------------------

  /** @brief Cross entropy between probability vectors
   *
   *  Given a predicted distribution @f$y@f$ and ground truth
   *  distribution @f$\hat{y}@f$,
   *  @f[ CE(y,\hat{y}) = - \sum\limits_{i} \hat{y}_i \log y_i @f]
   */
  message CrossEntropy {
    /// Advanced option for distconv
    bool use_labels = 1;
  }
  /**
   *  Given a prediction @f$y@f$ and ground truth @f$\hat{y}@f$,
   *  @f[
   *    MSE(y,\hat{y})
   *      = \frac{1}{n} \sum\limits_{i=1}^{n} (y_i - \hat{y}_i)^2
   *  @f]
   */
  message MeanSquaredError {}
  /**
   *  Given a prediction @f$y@f$ and ground truth @f$\hat{y}@f$,
   *  @f[
   *    MAE(y,\hat{y})
   *      = \frac{1}{n} \sum\limits_{i=1}^{n} | y_i - \hat{y}_i |
   *  @f]
   */
  message MeanAbsoluteError {}
  /** @brief 0-1 loss function
   *
   *  Requires two inputs, which are respectively interpreted as
   *  prediction scores and as a one-hot label vector. The output is
   *  one if the top entries in both inputs are in the same position
   *  and is otherwise zero. Ties are broken in favor of entries with
   *  smaller indices.
   *  This is primarily intended for use as a metric since it is not
   *  differentiable.
   */
  message CategoricalAccuracy {}
  /**
   *  Requires two inputs, which are respectively interpreted as
   *  prediction scores and as a one-hot label vector. The output is
   *  one if the corresponding label matches one of the top-k
   *  prediction scores and is otherwise zero. Ties in the top-k
   *  prediction scores are broken in favor of entries with smaller
   *  indices.
   */
  message TopKCategoricalAccuracy {
    int64 k = 1;
  }
  /** @brief Square of L2 vector norm
   *
   *  @f[ \lVert x\rVert_2^2 = \sum\limits_{i} x_i^2 @f]
   */
  message L2Norm2 {}
  /** @brief L1 vector norm
   *
   *  @f[ \lVert x\rVert_1 = \sum\limits_{i} | x_i | @f]
   */
  message L1Norm {}

  // ---------------------------
  // Regularization layers
  // ---------------------------

  /** @brief Channel-wise batch normalization, including scale/bias
   *
   *  Each input channel is normalized across the mini-batch to have
   *  zero mean and unit standard deviation. Learned scaling factors
   *  and biases are then applied. This uses the standard approach of
   *  maintaining the running mean and standard deviation (with
   *  exponential decay) for use at test time. See:
   *
   *  Sergey Ioffe and Christian Szegedy. "Batch Normalization:
   *  Accelerating Deep Network Training by Reducing Internal
   *  Covariate Shift." In International Conference on Machine
   *  Learning, pp. 448-456. 2015.
   */
  message BatchNormalization {
    /** @brief Decay factor for running statistics
     *  @details Default: 0.9
     */
    double decay = 1;
    /** @brief Small number for numerical stability
     *  @details Default: 1e-5
     */
    double epsilon = 4;
    /** @brief Size of process group for computing statistics
     *
     *  Default: 1
     *
     *  A group size of 1 implies purely local statistics. A negative
     *  group size indicates global statistics (i.e. statistics over
     *  the entire mini-batch).
     */
    int64 statistics_group_size = 6;

    /// Deprecated and unused
    double scale_init = 2;
    /// Deprecated and unsued
    double bias_init = 3;
    /// Deprecated
    string stats_aggregation = 5;

  }

  /** @brief Entry-wise batch normalization, including scale/bias
   *
   *  Each input entry is normalized across the mini-batch to have
   *  zero mean and unit standard deviation. This uses the standard
   *  approach of maintaining the running mean and standard deviation
   *  (with exponential decay) for use at test time. See:
   *
   *  Sergey Ioffe and Christian Szegedy. "Batch Normalization:
   *  Accelerating Deep Network Training by Reducing Internal
   *  Covariate Shift." In International Conference on Machine
   *  Learning, pp. 448-456. 2015.
   */
  message EntrywiseBatchNormalization {
    /** @brief Decay factor for running statistics
     *  @details Recommendation: 0.9
     */
    double decay = 1;
    /** @brief Small number for numerical stability
     *  @details Recommendation: 1e-5
     */
    double epsilon = 2;
  }

  /** @brief Scaled dropout for use with SELU activations.
   *
   *  A default keep probability of 0.95 is recommended. See:
   *
   *  Gunter Klambauer, Thomas Unterthiner, Andreas Mayr, and Sepp
   *  Hochreiter. "Self-normalizing neural networks." In Advances in
   *  Neural Information Processing Systems, pp. 971-980. 2017.
   */
  message SeluDropout {
    /// Recommendation: 0.95
    double keep_prob = 2;
    /// Default: 1.6732632423543772848170429916717
    double alpha = 3;
    /// Default: 1.0507009873554804934193349852946
    double scale = 4;
  }

  /**
   *  See:
   *
   *  Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. "ImageNet
   *  classification with deep convolutional neural networks." In
   *  Advances in Neural Information Processing Systems,
   *  pp. 1097-1105. 2012.
   */
  message LocalResponseNormalization {
    int64 window_width = 4;
    double lrn_alpha = 5;
    double lrn_beta = 6;
    double lrn_k = 7;
  }

  /** @brief Probabilistically drop tensor entries
   *
   *  The values multiplied by 1/(keep probability) at training time.
   *  Keep probabilities of 0.5 for fully-connected layers and 0.8 for
   *  input layers are good starting points. See:
   *
   *  Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya
   *  Sutskever, and Ruslan Salakhutdinov. "Dropout: a simple way to
   *  prevent neural networks from overfitting." The Journal of
   *  Machine Learning Research 15, no. 1 (2014): 1929-1958.
   */
  message Dropout {
    /** @brief Probability of keeping each tensor entry
     *  @details Recommendation: 0.5
     */
    double keep_prob = 2;
  }

  /** @brief Normalize over data samples
   *
   *  Each data sample is normalized to have zero mean and unit
   *  standard deviation. See:
   *
   *  Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton. "Layer
   *  normalization." arXiv preprint arXiv:1607.06450 (2016).
   *
   *  Note that this layer does not apply an entry-wise scale and bias
   *  like in the paper. Use the entry-wise scale/bias layer to
   *  reproduce that functionality.
   */
  message LayerNorm {
    /** @brief Small number to avoid division by zero.
     *  @details Default: 1e-5
     */
    google.protobuf.DoubleValue epsilon = 1;
  }

  /** @brief Normalize over data channels
   *
   *  Each channel within a data sample is normalized to have zero
   *  mean and unit standard deviation. See:
   *
   *  Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky. "Instance
   *  normalization: The missing ingredient for fast stylization."
   *  arXiv preprint arXiv:1607.08022 (2016).
   *
   *  This is equivalent to applying layer normalization independently
   *  to each channel. Note that this layer does not apply a
   *  channel-wise scale and bias. Use the channel-wise scale/bias
   *  layer to reproduce that functionality.
   */
  message InstanceNorm {
    /** @brief Small number to avoid division by zero.
     *  @details Default: 1e-5
     */
    google.protobuf.DoubleValue epsilon = 1;
  }

  // ---------------------------
  // I/O layers
  // ---------------------------

  /** @brief Data tensor from data reader */
  message Input {
    /** @brief Data tensor name
     *
     *  Legacy values are "samples", "labels", "responses".
     */
    string data_field = 1;
  }

  // ---------------------------
  // Transform layers
  // ---------------------------

  message Reshape {
    int64 num_dims = 1; //DEPRECATED
    string dims = 2; //should be space-separated list of ints, e.g, "2 6 7"
  }

  message Pooling {
    int64 num_dims = 1;

    bool has_vectors = 2;

    //these are used if has_vectors = true
    string pool_dims = 4; //should be space-separated list, e.g, "2 2 3"
    string pool_pads = 5; //should be space-separated list, e.g, "2 2 3"
    string pool_strides = 6; //should be space-separated list, e.g, "2 2 3"

    //these are used if has_vectors = false
    int64 pool_dims_i = 10;
    int64 pool_pads_i = 11;
    int64 pool_strides_i = 12;

    //pool_mode should be one of: max, average, average_no_pad
    //see: lbann/include/lbann/lbann_base.hpp
    string pool_mode = 7;
  }

  /** @brief Transpose of pooling layer
   *
   *  Requires that a pooling layer is set as the hint layer.
   *
   *  @warning This has not been well maintained and is probably
   *  broken.
   *  @todo GPU support.
   */
  message Unpooling {
    int64 num_dims = 1;
  }


  message Concatenation {
    int64 axis = 1;
  }

  message Slice {
    int64 axis = 1;
    string slice_points = 2; //should be space-separated list of ints, e.g, "2 6 7"
    //the following is for jag_conduit_hdf5;
    string get_slice_points_from_reader = 4;
    bool get_slice_points_from_reader_bool = 5;
  }

  message Split {
  }

  message Sum {
  }

  message Cross_Grid_Sum_Slice {
  }

  message Cross_Grid_Sum {
  }

  message WeightedSum {
    string scaling_factors = 1;
    //should be a space-separated list of doubles, e.g. "1.0 2.0 -1.0"
  }

  message Hadamard {
  }

  message Constant {
    double value=1;
    string num_neurons=2;
  }

  /** @brief Reduce tensor to scalar. */
  message Reduction {
    string mode=1; // "sum" (default) or "mean"
  }

  message Evaluation {
  }

  message Gaussian {
    double mean = 1;
    double stdev = 2;
    string neuron_dims = 3;
    bool training_only = 4;
  }

  message Bernoulli {
    double prob = 1;
    string neuron_dims = 2;
  }

  message Uniform {
    double min = 1;
    double max = 2;
    string neuron_dims = 3;
    bool training_only = 4;
  }


  message Crop {
    string dims = 3;
  }

  message CategoricalRandom {
  }

  message DiscreteRandom {
    string values = 1;
    string dims = 2;
  }

  message Dummy {
  }

  message StopGradient {
  }

  message InTopK {
    int64 k = 1;
  }

  message Sort {
    bool descending = 1;
  }

  message WeightsLayer {
    string dims = 1;
  }

  message Tessellate {
    string dims = 1;
  }

  /** @brief Scatter values to specified tensor indices.
    *
    *  @f[
    *    y[\text{ind}[i]] = x[i]
    *  @f]
    *
    *  If 2D and Axis = 0
    *  @f[
    *    y[\text{ind}[i],j] = x[i,j]
    *  @f]
    *
    *  If 2D and Axis = 1
    *  @f[
    *    y[i,\text{ind}[j]] = x[i,j]
    *  @f]
    *
    *  The first input tensor is the values and the second is the
    *  indices. For the 1D case the inputs must have the same dimensions.
    *  For the 2D case, the inputs must have either the same number of
    *  columns (axis=0) or the same number of rows (axis=1). If
    *  an index is out-of-range, it is ignored.
    *
    *  @note: In the 2D case the output dimensions change depending on the
    *  axis. For an (m,n) values input, the output dims are expected to
    *  be (*,n) for Axis == 0 and (m,*) for Axis == 1.
    *
    *  @todo Only flat tensors are currently supported. For higher-order
    *  tensors, PyTorch
    *  (https://pytorch.org/docs/master/tensors.html#torch.Tensor.scatter_)
    *  and TensorFlow
    *  (https://www.tensorflow.org/api_docs/python/tf/scatter_nd) will
    *  scatter along a specified dimension.
    */
  message Scatter {
    /// Output tensor dimensions
    string dims = 1;
    google.protobuf.UInt64Value axis = 2;
  }

  /** @brief Gather values from specified tensor indices.
    *
    *  @f[
    *    y[i] = x[\text{ind}[i]]
    *  @f]
    *
    *  If 2D and Axis = 0
    *  @f[
    *    y[i,j] = x[\text{ind}[i],j]
    *  @f]
    *
    *  If 2D and Axis = 1
    *  @f[
    *    y[i,j] = x[i,\text{ind}[j]]
    *  @f]
    *
    *  The first input tensor is the values and the second is the
    *  indices. The two input tensors must have the same number of
    *  dimensions, and the output tensor will have the same dimensions as
    *  the index tensor. If an index is out-of-range, the corresponding
    *  output is set to zero.
    *
    *  @note: In the 2D case, the output dimension changes according
    *  to the axis. For an (m,n) values input, and a (k) indices input,
    *  the output tensor will be (k,n) for Axis == 0 and (m, k) for
    *  Axis == 1
    */
  message Gather {

    google.protobuf.UInt64Value axis = 1;
  }

  /** @brief Sum of tensor entries along batch dimension
    *
    *  Output tensor has same shape as input tensor.
    */
  message BatchwiseReduceSum {}

  // ---------------------------
  // Learning layers
  // ---------------------------

  /** @brief Affine transformation
   *
   *  Flattens the input tensor, multiplies with a weights matrix, and
   *  optionally applies an entry-wise bias. Following the
   *  column-vector convention:
   *    @f[ y = W * \text{vec}(x) + b @f]
   *
   *  Two weights are required if bias is applied: the linearity and the
   *  bias. Only the linearity weights are required if bias is not
   *  applied. If weights aren't provided, the linearity weights are
   *  initialized with He normal initialization and the bias weights are
   *  initialized to zero.
   */
  message FullyConnected {
    // Output tensor size
    int64 num_neurons = 1;
    // Whether to apply entry-wise bias
    bool has_bias = 2;
    // Whether to apply transpose of weights matrix
    bool transpose = 3;
  }

  message Convolution {
    int64 num_dims = 1;
    int64 num_output_channels = 4;
    int64 num_groups = 3;

    bool has_vectors = 2;

    // these are used if has_vector = true
    string conv_dims = 5; //should be space-separated list, e.g, "2 2 3"
    string conv_pads = 6;  //should be space-separated list, e.g, "2 2 3"
    string conv_strides = 7; //should be space-separated list, e.g, "2 2 3"
    string conv_dilations = 8;  //should be space-separated list, e.g. "2 3 3"

    // these are used if has_vector = false
    int64 conv_dims_i = 50;
    int64 conv_pads_i = 60;
    int64 conv_strides_i = 70;
    int64 conv_dilations_i = 80;

    string weight_initialization = 9;     //DEPRECATED
    bool has_bias = 10;                   //default: true
    double bias_initial_value = 11;       //default: 0
    double l2_regularization_factor = 12; //default: 0

    // This field is ignored for non-GPU layers.
    ConvTensorOpsMode conv_tensor_op_mode = 13;
  }

  message Deconvolution {
    int64 num_dims = 1;
    int64 num_output_channels = 4;
    int64 num_groups = 3;

    bool has_vectors = 2;

    // these are used if has_vector = true
    string conv_dims = 5; //should be space-separated list, e.g, "2 2 3"
    string conv_pads = 6;  //should be space-separated list, e.g, "2 2 3"
    string conv_strides = 7; //should be space-separated list, e.g, "2 2 3"
    string conv_dilations = 8;  //should be space-separated list, e.g. "2 3 3"

    // these are used if has_vector = false
    int64 conv_dims_i = 50;
    int64 conv_pads_i = 60;
    int64 conv_strides_i = 70;
    int64 conv_dilations_i = 80;

    string weight_initialization = 9;     //DEPRECATED
    bool has_bias = 10;                   //default: true
    double bias_initial_value = 11;       //default: 0
    double l2_regularization_factor = 12; //default: 0

    // This field is ignored for non-GPU layers.
    ConvTensorOpsMode conv_tensor_op_mode = 13;
  }

  /** @brief Lookup table to embedding vectors.
   *
   *  Takes a scalar input, interprets it as an index, and outputs the
   *  corresponding vector. The number of embedding vectors and the
   *  size of vectors are fixed. If the index is out-of-range, then
   *  the output is a vector of zeros.
   *
   *  The embedding vectors are stored in an
   *  @f$ \text{embedding_dim} \times \text{num_embeddings} @f$
   *  weights matrix. Note that this is the transpose of the weights
   *  in the PyTorch embedding layer.
   */
  message Embedding {
    /// Size of dictionary of embeddings
    int64 num_embeddings = 1;
    /// Size of embedding vectors
    int64 embedding_dim = 2;
    /** If the padding index is set, then the corresponding embedding
     *  vector is initialized with zeros. The objective function
     *  gradient w.r.t. this embedding vector is always zero.
     */
    google.protobuf.Int64Value padding_idx = 3;
  }

  message ChannelwiseScaleBias {}
  message EntrywiseScaleBias {}

  /** @brief Apply affine transformation to tensor channels.
   *
   *  The input tensor is sliced along the first tensor dimension (the
   *  "channel" dimension for image data in CHW format) and the same
   *  affine transformation is applied to each slice. Following a
   *  row-vector convention:
   *    @f[ y(i,*) = \text{vec}( x(i,*) ) W^T + b @f]
   *
   *  Two weights are required if bias is applied: the linearity and the
   *  bias. Only the linearity weights are required if bias is not
   *  applied. If weights aren't provided, the linearity weights are
   *  initialized with He normal initialization and the bias weights are
   *  initialized to zero.
   *
   */
  message ChannelwiseFullyConnected {
    /// Output tensor dimensions, excluding the first dimension.
    repeated uint64 output_channel_dims = 1;
    /** @brief Whether to apply bias.
     *  @details Default: true
     */
    google.protobuf.BoolValue bias = 2;
    /** @brief Whether to apply transpose of weights matrix.
     *  @details Default: false
     */
    google.protobuf.BoolValue transpose = 3;
  }

  /** @brief Stacked gated recurrent unit
   *
   *  Expects two inputs: a 2D input sequence (
   *  @f$ \text{sequence\_length}\times\text{input\_size} @f$ )
   *  and a 2D initial hidden state (
   *  @f$ \text{num\_layers}times\text{hidden\_size} @f$ ).
   *
   *  Uses four weights per GRU cell: "ih\_matrix" (
   *  @f$ 3 \text{hidden\_size}\times\text{input\_size} @f$ for layer
   *  0 and @f$ 3 \text{hidden\_size}\times\text{hidden\_size} for
   *  other layers), "hh\_matrix" (
   *  @f$ 3 \text{hidden\_size}\times\text{hidden\_size} @f$ ),
   *  "ih_bias" ( @f$ 3 \text{hidden\_size} @f$ ),
   *  "hh_bias" ( @f$ 3 \text{hidden\_size} @f$ ).
   *
   *  Currently only supported on GPU. Requires at least CUDA 11.0 and
   *  cuDNN 8.0.4.
   *
   *  @todo Support CPU
   *  @todo Support bidirectional RNNs
   */
  message GRU {
    /// Size of each hidden state and output vector
    uint64 hidden_size = 1;
    /// Number of stacked GRU cells (default: 1)
    google.protobuf.UInt64Value num_layers = 2;
  }

  // ---------------------------
  // Image layers
  // ---------------------------

  message BilinearResize {
    int64 height = 1;
    int64 width = 2;
  }

  /** @brief Rotate a image clockwise around its center
   *
   *  Expects two inputs: a 3D image tensor in CHW format and a scalar
   *  rotation angle.
   */
  message Rotation {}

  /** @brief Rotate a image clockwise around its center, then shear , then translate
   *
   *  Expects 4 inputs: a 3D image tensor in CHW format, a scalar
   *  rotation angle, a tensor for (X,Y) shear factor, a tensor
   *  for (X,Y) translate.
   */
  message CompositeImageTransformation {}

  // ---------------------------
  // Miscellaneous layers
  // ---------------------------

  message Covariance {
    bool biased = 1; //Whether to use a biased covariance estimate
  }
  message Variance {
    bool biased = 1; //Whether to use a biased variance estimate
  }
  message ChannelwiseMean {}
  message MiniBatchIndex {}
  message MiniBatchSize {}

  // Get index of maximum-value tensor entry
  //
  // Expects a 1-D input tensor. If multiple entries have the same
  // maximum value, outputs the index of the first one.
  message Argmax {}

  // Get index of minimum-value tensor entry
  //
  // Expects a 1-D input tensor. If multiple entries have the same
  // minimum value, outputs the index of the first one.
  message Argmin {}

  // Convert index to a one-hot vector
  //
  // Expects a scalar input tensor and outputs a 1-D output tensor.
  // The input is interpreted as an index, and output entries are one
  // if they correspond to that index and zero otherwise. If the input
  // is outside [0,size), then the output is all zeros.
  message OneHot {
    // Size of one-hot vector
    int64 size = 1;
  }

  message ChannelwiseSoftmax {}

  /** @brief Embedding layer with distributed weights.
   *
   *  @warning This is extremely experimental.
   */
  message DistEmbedding {

    /** Size of dictionary of embeddings. */
    int64 num_embeddings = 1;
    /** Size of embedding vectors. */
    int64 embedding_dim = 2;

    /** Perform sparse SGD during backprop.
     *
     *  Bypasses optimizer class.
     */
    bool sparse_sgd = 3;
    /** SGD learning rate. */
    double learning_rate = 4;

    /** Perform a blocking barrier at the beginning of forward prop.
     *
     *  This layer performs synchronization with non-blocking barriers
     *  to ensure the correctness of asynchronous communication.
     *  However, gradient checking changes the embedding values without
     *  performing any synchronization. The quickest fix is to do a
     *  blocking barrier at the beginning of forward prop to make sure
     *  that all the embeddings are ready to be accessed.
     *
     *  @todo Think of a way to avoid this synchronization.
     */
    bool barrier_in_forward_prop = 5;

  }

  /** @brief Apply a hash function to get uniformly distributed values
   *
   *  Each input entry is hashed with MD5 and scaled to [0,1).
   *
   *  @warning Currently only supported on GPU.
   */
  message UniformHash {}

  /** @brief L2 norm of each row of a weights matrix.
   *
   *  @warning This layer is experimental and finnicky. It is intended
   *  for use with the matrix weights from a fully-connected layer, and
   *  other use-cases may have strange behavior.
   *
   *  Given a weights object, this layer computes the L2 norm for each
   *  row of the underlying matrix. Note that the internal matrix may
   *  have different dimensions than the logical weight dimensions.
   *
   *  This layer expects to have one weights object. During setup, that
   *  weights object should be initialized by another layer before this
   *  layer's setup phase. Setting a "hint layer" may be necessary to
   *  enforce this ordering.
   */
  message RowwiseWeightsNorms {}

} // message Layer

//========================================================================
// Parallel strategies for generalized layer-wise parallelism
//========================================================================
message ParallelStrategy {
  int64 sample_groups = 1;
  int64 sample_splits = 2;
  int64 height_groups = 3;
  int64 height_splits = 4;
  int64 width_groups = 5;
  int64 width_splits = 6;
  int64 channel_groups = 7;
  int64 channel_splits = 8;
  int64 filter_groups = 9;
  int64 filter_splits = 10;
  // For fully-connected layers.
  int64 replications = 11;
  int64 procs_per_replica = 12;
  int64 depth_groups = 13;
  int64 depth_splits = 14;
  int64 sub_branch_tag = 15;
  int64 sub_branch_resource_percentage = 16;
  bool enable_subgraph = 17;
}

// =============================================
// Deprecated messages
// =============================================

/// Deprecated
message WeightsShape {
  repeated int64 dim = 1 [packed = true];
}
/// Deprecated
message WeightsData {
  WeightsShape shape = 5;
  string name = 1;
  int64 height = 2;
  int64 width = 3;
  repeated float data = 4 [packed=true];
  Imcomm imcomm = 55;
}
/// Deprecated
enum Imcomm {
  DEFAULT = 0; //add Layer to Imcomm callback if all_learning_layers = true in
               //the CallbackImComm
  EXCLUDE = 1; //*do not* add Layer to Imcomm callback if all_learning_layers = true in
               //the CallbackImComm
  INCLUDE = 2;  //add Layer to Imcomm callback regardless of whether all_learning_layers
                //in the CallbackImComm is set to true or false
}
