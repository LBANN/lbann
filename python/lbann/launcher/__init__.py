import datetime
import os
import os.path
import subprocess
import lbann
import lbann.proto
import lbann.launcher.slurm
import lbann.launcher.lsf
from lbann.util import make_iterable

# ==============================================
# Run experiments
# ==============================================

def run(model, data_reader, optimizer,
        experiment_dir=None,
        nodes=1,
        procs_per_node=1,
        time_limit=None,
        scheduler=None,
        job_name='lbann',
        system=None,
        partition=None,
        account=None,
        reservation=None,
        launcher_args=[],
        lbann_args=[],
        environment={},
        setup_only=False):
    """Run LBANN experiment.

    This is intended to interface with job schedulers on HPC
    clusters. It will either submit a batch job (if on a login node)
    or run with an existing node allocation (if on a compute
    node). Behavior may vary across schedulers.

    If an experiment directory is not provided, a timestamped
    directory is created (by default in the current working
    directory). The location of autogenerated experiment directories
    can be set with the environment variable `LBANN_EXPERIMENT_DIR`.

    Args:
        model (lbann.model.Model or lbann_pb2.Model): Neural network
            model.
        data_reader (lbann_pb2.DataReader): Data reader.
        optimizer (lbann.model.Optimizer or lbann_pb2.Optimizer):
            Default optimizer for model.
        experiment_dir (str, optional): Experiment directory.
        nodes (int, optional): Number of compute nodes.
        procs_per_node (int, optional): Number of processes per compute
            node.
        time_limit (int, optional): Job time limit, in minutes.
        scheduler (str, optional): Job scheduler.
        job_name (str, optional): Batch job name.
        system (str, optional): Target system.
        partition (str, optional): Scheduler partition.
        account (str, optional): Scheduler account.
        reservation (str, optional): Scheduler reservation name.
        launcher_args (str, optional): Command-line arguments to
            launcher.
        lbann_args (str, optional): Command-line arguments to LBANN
            executable.
        environment (dict of {str: str}, optional): Environment
            variables.
        setup_only (bool, optional): If true, the experiment is not
            run after the experiment directory is initialized.

    Returns:
        int: Exit status from scheduler. This is really only
            meaningful if LBANN is run on an existing node
            allocation. If a batch job is submitted, the scheduler
            will probably return 0 trivially.

    """

    # Create batch script generator
    script = make_batch_script(work_dir=experiment_dir,
                               nodes=nodes,
                               procs_per_node=procs_per_node,
                               time_limit=time_limit,
                               scheduler=scheduler,
                               job_name=job_name,
                               system=system,
                               partition=partition,
                               account=account,
                               reservation=reservation,
                               launcher_args=launcher_args,
                               environment=environment)

    # Check for an existing job allocation
    has_allocation = False
    if isinstance(script, lbann.launcher.slurm.SlurmBatchScript):
        has_allocation = 'SLURM_JOB_ID' in os.environ
    if isinstance(script, lbann.launcher.lsf.LSFBatchScript):
        has_allocation = 'LSB_JOBID' in os.environ

    # Batch script prints start time
    script.add_command('date | sed "s/^/Started at /"')

    # Batch script invokes LBANN
    lbann_command = lbann.lbann_exe()
    lbann_command += ' ' + ' '.join(make_iterable(lbann_args))
    prototext_file = os.path.join(script.work_dir, 'experiment.prototext')
    lbann.proto.save_prototext(prototext_file,
                               model=model,
                               data_reader=data_reader,
                               optimizer=optimizer)
    lbann_command += ' --prototext=' + prototext_file
    script.add_parallel_command(lbann_command)

    # Batch script prints finish time
    script.add_command('date | sed "s/^/Finished at /"')

    # Write, run, or submit batch script
    status = 0
    if setup_only:
        script.write()
    elif has_allocation:
        status = script.run()
    else:
        status = script.submit()
    return status

def make_batch_script(script_file=None,
                      work_dir=None,
                      nodes=1,
                      procs_per_node=1,
                      time_limit=None,
                      scheduler=None,
                      job_name='lbann',
                      system=None,
                      partition=None,
                      account=None,
                      reservation=None,
                      launcher_args=[],
                      environment={}):

    # Try detecting job scheduler if not provided
    if not scheduler:
        try:
            subprocess.call(['sbatch', '--version'],
                            stdout=subprocess.DEVNULL,
                            stderr=subprocess.DEVNULL)
            scheduler = 'slurm'
        except:
            pass
    if not scheduler:
        try:
            subprocess.call(['bsub', '-V'],
                            stdout=subprocess.DEVNULL,
                            stderr=subprocess.DEVNULL)
            scheduler = 'lsf'
        except:
            pass
    if not scheduler:
        raise RuntimeError('could not detect job scheduler')

    # Create work directory if not provided
    if not work_dir:
        if 'LBANN_EXPERIMENT_DIR' in os.environ:
            work_dir = os.environ['LBANN_EXPERIMENT_DIR']
        else:
            work_dir = os.path.join(os.getcwd())
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        work_dir = os.path.join(work_dir,
                                '{}_{}'.format(timestamp, job_name))
        i = 1
        while os.path.lexists(work_dir):
            i += 1
            work_dir = os.path.join(
                os.path.dirname(work_dir),
                '{}_{}_{}'.format(timestamp, job_name, i))
    work_dir = os.path.realpath(work_dir)
    os.makedirs(work_dir, exist_ok=True)

    # Create batch script generator
    if not script_file:
        script_file = os.path.join(work_dir, 'batch.sh')
    script = None
    if scheduler.lower() in ('slurm', 'srun', 'sbatch'):
        script = lbann.launcher.slurm.SlurmBatchScript(
            script_file=script_file,
            work_dir=work_dir,
            nodes=nodes,
            procs_per_node=procs_per_node,
            time_limit=time_limit,
            job_name=job_name,
            partition=partition,
            account=account,
            launcher_args=launcher_args)
    elif scheduler.lower() in ('lsf', 'jsrun', 'bsub'):
        script = lbann.launcher.lsf.LSFBatchScript(
            script_file=script_file,
            work_dir=work_dir,
            nodes=nodes,
            procs_per_node=procs_per_node,
            time_limit=time_limit,
            job_name=job_name,
            partition=partition,
            account=account,
            reservation=reservation,
            launcher_args=launcher_args)
    else:
        raise RuntimeError('unsupported job scheduler ({})'
                           .format(scheduler))

    # Set batch script environment
    for variable, value in environment.items():
        script.add_command('export {0}={1}'.format(variable, value))

    return script
