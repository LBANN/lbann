<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>LBANN: Todo List</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">LBANN
   &#160;<span id="projectnumber">@LBANN_MAJOR_VERSION@.@LBANN_MINOR_VERSION@</span>
   </div>
   <div id="projectbrief">LivermoreBigArtificialNeuralNetworkToolkit</div>
  </td>
   <td>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
</td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('todo.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Todo List </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><dl class="reflist">
<dt><a class="anchor" id="_todo000015"></a>Member <a class="el" href="base_8hpp.html#adeeaddd10bd31df0cae7cb0fcae45d5c">_to_string</a>  (execution_mode m)</dt>
<dd>this should be an lbann_exception but then the class has to move to resolve dependencies  </dd>
<dt><a class="anchor" id="_todo000016"></a>Member <a class="el" href="namespacelbann_1_1Al.html#acac3d42323b313e89a60a27f00554661">lbann::Al::nccl_backend</a>  </dt>
<dd>MPI-CUDA backend  </dd>
<dt><a class="anchor" id="_todo000008"></a>Member <a class="el" href="namespacelbann.html#a085b697db535c10a6fd6689cc4445bd4">lbann::columnwise_mean_and_stdev</a>  (const AbsDistMat &amp;data, AbsDistMat &amp;means, AbsDistMat &amp;stdevs)</dt>
<dd>Numerically stable implementation  </dd>
<dt><a class="anchor" id="_todo000007"></a>Member <a class="el" href="namespacelbann.html#ab043d2f2f9dea0ee861aff3a38216b24">lbann::columnwise_sums_and_sqsums</a>  (const AbsDistMat &amp;data, AbsDistMat &amp;sums, AbsDistMat &amp;sqsums)</dt>
<dd>Numerically stable implementation  </dd>
<dt><a class="anchor" id="_todo000019"></a>Member <a class="el" href="classlbann_1_1generic__data__reader.html#a06fb58d1c0b84b8c76f5b4d160751f34">lbann::generic_data_reader::get_num_iterations_per_epoch</a>  () const</dt>
<dd>BVE FIXME merge this with alternate approach  </dd>
<dt><a class="anchor" id="_todo000018"></a>Member <a class="el" href="classlbann_1_1generic__data__reader.html#a91573d9599b503a6bdf2939e69659e8b">lbann::generic_data_reader::set_num_iterations_per_epoch</a>  (int num_iterations_per_epoch)</dt>
<dd>BVE FIXME merge this with alternate approach  </dd>
<dt><a class="anchor" id="_todo000020"></a>Member <a class="el" href="classlbann_1_1generic__input__layer.html#ad0b8ea79bc508bd227e08124359531c8">lbann::generic_input_layer::fp_setup_data</a>  (int mini_batch_size) override</dt>
<dd>This functionality should probably be moved elsewhere  </dd>
<dt><a class="anchor" id="_todo000023"></a>Member <a class="el" href="classlbann_1_1generic__target__layer.html#a57a60f5a28c9fb78d5151801123d4dba">lbann::generic_target_layer::fp_compute</a>  () override</dt>
<dd>should this distribute the entire matrix even if there is only a partial mini-batch  </dd>
<dt><a class="anchor" id="_todo000025"></a>Member <a class="el" href="classlbann_1_1generic__target__layer.html#a2d9f6ac689171acf0caceed3ed4f7ef9">lbann::generic_target_layer::loadFromCheckpoint</a>  (int fd, const char *filename, size_t *bytes) override</dt>
<dd>should probably save m_shared_data_reader  </dd>
<dt><a class="anchor" id="_todo000022"></a>Member <a class="el" href="classlbann_1_1generic__target__layer.html#a7c15e3fe4f1fd7f0ccdbc4c3ed8c793e">lbann::generic_target_layer::operator=</a>  (const <a class="el" href="classlbann_1_1generic__target__layer.html">generic_target_layer</a> &amp;other)</dt>
<dd>Should this be a shallow copy?  </dd>
<dt><a class="anchor" id="_todo000024"></a>Member <a class="el" href="classlbann_1_1generic__target__layer.html#aff8b79ff0392bd78c44a5a4f6b6ef549">lbann::generic_target_layer::saveToCheckpoint</a>  (int fd, const char *filename, size_t *bytes) const override</dt>
<dd>should probably save m_shared_data_reader  </dd>
<dt><a class="anchor" id="_todo000031"></a>Member <a class="el" href="namespacelbann.html#a8987701a637ff0e678114aa77e9c4d40">lbann::init_data_seq_random</a>  (int seed)</dt>
<dd>Support saving/restoring the generator's state. This is directly supported via the &gt;&gt; and &lt;&lt; operators on the generator (reading/writing from/to a stream).  </dd>
<dt><a class="anchor" id="_todo000030"></a>Member <a class="el" href="namespacelbann.html#acef152f20e422b3aea1a3c1691a533ac">lbann::init_random</a>  (int seed, <a class="el" href="classlbann_1_1lbann__comm.html">lbann_comm</a> *comm)</dt>
<dd>Support saving/restoring the generator's state. This is directly supported via the &gt;&gt; and &lt;&lt; operators on the generator (reading/writing from/to a stream).  </dd>
<dt><a class="anchor" id="_todo000021"></a>Member <a class="el" href="classlbann_1_1input__layer.html#aad8b042899d86f5b7904d9d2653b5181">lbann::input_layer&lt; T_io_buffer, T_layout &gt;::input_layer</a>  (<a class="el" href="classlbann_1_1lbann__comm.html">lbann_comm</a> *comm, int num_parallel_readers, std::map&lt; execution_mode, generic_data_reader *&gt; data_readers, bool data_set_spans_models=true, bool for_regression=false)</dt>
<dd>make the map and vector references  </dd>
<dt><a class="anchor" id="_todo000001"></a>Member <a class="el" href="classlbann_1_1lbann__callback__debug__io.html#aa3d2a6fb4d7375c05ece0058224ea792">lbann::lbann_callback_debug_io::on_epoch_begin</a>  (model *m) override</dt>
<dd>The use of execution_mode invalid needs to be reconsidered  </dd>
<dt><a class="anchor" id="_todo000002"></a>Member <a class="el" href="classlbann_1_1lbann__callback__ltfb.html#a7548166d170eda00e4e0cba6626a1a78">lbann::lbann_callback_ltfb::setup</a>  (model *m) override</dt>
<dd>Support LTFB with different models  </dd>
<dt><a class="anchor" id="_todo000029"></a>Member <a class="el" href="classlbann_1_1lbann__quantizer.html#a22b898932caed41ccf24abcb67c00ba1">lbann::lbann_quantizer::get_adaptive_quantization_copy_threads</a>  (El::Int width)</dt>
<dd>Make this configurable at compile time.  </dd>
<dt><a class="anchor" id="_todo000028"></a>Member <a class="el" href="classlbann_1_1lbann__quantizer.html#aaa0c20f755437130172c40ca8e95bc3f">lbann::lbann_quantizer::get_adaptive_quantization_threads</a>  (El::Int width)</dt>
<dd>Make this configurable at compile time.  </dd>
<dt><a class="anchor" id="_todo000026"></a>Member <a class="el" href="classlbann_1_1model.html#ad0cdcba177434b52dc9c4a97be183a92">lbann::model::get_cur_step</a>  () const</dt>
<dd>This should be renamed to get_cur_training step and replaced with one that returns the current based on execution mode  </dd>
<dt><a class="anchor" id="_todo000004"></a>Member <a class="el" href="namespacelbann_1_1proto.html#a00597c8b7450c389847980cf6934a619">lbann::proto::construct_callback</a>  (<a class="el" href="classlbann_1_1lbann__comm.html">lbann_comm</a> *comm, const lbann_data::Callback &amp;proto_cb, std::map&lt; execution_mode, generic_data_reader *&gt; &amp;data_readers, std::vector&lt; Layer *&gt; layer_list, std::vector&lt; weights *&gt; weights_list, <a class="el" href="classlbann_1_1lbann__summary.html">lbann_summary</a> *summarizer)</dt>
<dd><p class="startdd"></p>
<p>Initialize weights </p>
<p>Initialize weights </p>
<p class="enddd">Initialize weights  </p>
</dd>
<dt><a class="anchor" id="_todo000006"></a>Member <a class="el" href="namespacelbann_1_1proto.html#a7e4b0a66836712b1713ae4a121453cde">lbann::proto::construct_layer</a>  (<a class="el" href="classlbann_1_1lbann__comm.html">lbann_comm</a> *comm, std::map&lt; execution_mode, generic_data_reader *&gt; &amp;data_readers, int num_parallel_readers, <a class="el" href="classlbann_1_1cudnn_1_1cudnn__manager.html">cudnn::cudnn_manager</a> *cudnn, const lbann_data::Layer &amp;proto_layer)</dt>
<dd>Support for GPU model-parallel layers  </dd>
<dt><a class="anchor" id="_todo000010"></a>Member <a class="el" href="namespacelbann.html#a9b1fd2f864f421aa0bd9f8582ad87c14">lbann::rowwise_mean_and_stdev</a>  (const AbsDistMat &amp;data, AbsDistMat &amp;means, AbsDistMat &amp;stdevs)</dt>
<dd>Numerically stable implementation  </dd>
<dt><a class="anchor" id="_todo000009"></a>Member <a class="el" href="namespacelbann.html#a6b342b3e5b3fbb08b97b6d90aa68d121">lbann::rowwise_sums_and_sqsums</a>  (const AbsDistMat &amp;data, AbsDistMat &amp;sums, AbsDistMat &amp;sqsums)</dt>
<dd>Numerically stable implementation  </dd>
<dt><a class="anchor" id="_todo000027"></a>Member <a class="el" href="classlbann_1_1sequential__model.html#aa405c653dae867e862475e13b9df1db0">lbann::sequential_model::load_from_checkpoint</a>  (int fd, const char *filename, size_t *bytes)</dt>
<dd>This is old and likely broken  </dd>
<dt><a class="anchor" id="_todo000003"></a>Member <a class="el" href="classlbann_1_1siamese__model.html#a7ff41cffb060500605124959f1a2a6cf">lbann::siamese_model::setup_layer_topology</a>  () override</dt>
<dd>Handle case where heads have already been initialized.  </dd>
<dt><a class="anchor" id="_todo000011"></a>Member <a class="el" href="classlbann_1_1weights.html#a1a2631987f38d32a90fbee61053a04cc">lbann::weights::write_proto</a>  (lbann_data::WeightsData *proto) const</dt>
<dd><p class="startdd">What if weights are on GPU? </p>
<p>What if world master is not process 0? </p>
<p>OpenMP parallelization </p>
<p class="enddd">Our matrices are column-major while Numpy expects row-major matrices. This row-wise iteration is fine for matrices and column vectors, but it can mess up the order of the weights if a high-dimensional tensor is represented as a matrix. This is what we need for quantization on convolution kernel weights. </p>
</dd>
</dl>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Tue Apr 24 2018 15:13:30 for LBANN by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
