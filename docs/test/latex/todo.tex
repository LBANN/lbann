
\begin{DoxyRefList}
\item[\label{todo__todo000015}%
\Hypertarget{todo__todo000015}%
Member \hyperlink{base_8hpp_adeeaddd10bd31df0cae7cb0fcae45d5c}{\+\_\+to\+\_\+string} (execution\+\_\+mode m)]this should be an lbann\+\_\+exception but then the class has to move to resolve dependencies  
\item[\label{todo__todo000016}%
\Hypertarget{todo__todo000016}%
Member \hyperlink{namespacelbann_1_1Al_acac3d42323b313e89a60a27f00554661}{lbann\+:\+:Al\+:\+:nccl\+\_\+backend} ]M\+P\+I-\/\+C\+U\+DA backend  
\item[\label{todo__todo000008}%
\Hypertarget{todo__todo000008}%
Member \hyperlink{namespacelbann_a085b697db535c10a6fd6689cc4445bd4}{lbann\+:\+:columnwise\+\_\+mean\+\_\+and\+\_\+stdev} (const Abs\+Dist\+Mat \&data, Abs\+Dist\+Mat \&means, Abs\+Dist\+Mat \&stdevs)]Numerically stable implementation  
\item[\label{todo__todo000007}%
\Hypertarget{todo__todo000007}%
Member \hyperlink{namespacelbann_ab043d2f2f9dea0ee861aff3a38216b24}{lbann\+:\+:columnwise\+\_\+sums\+\_\+and\+\_\+sqsums} (const Abs\+Dist\+Mat \&data, Abs\+Dist\+Mat \&sums, Abs\+Dist\+Mat \&sqsums)]Numerically stable implementation  
\item[\label{todo__todo000019}%
\Hypertarget{todo__todo000019}%
Member \hyperlink{classlbann_1_1generic__data__reader_a06fb58d1c0b84b8c76f5b4d160751f34}{lbann\+:\+:generic\+\_\+data\+\_\+reader\+:\+:get\+\_\+num\+\_\+iterations\+\_\+per\+\_\+epoch} () const]B\+VE F\+I\+X\+ME merge this with alternate approach  
\item[\label{todo__todo000018}%
\Hypertarget{todo__todo000018}%
Member \hyperlink{classlbann_1_1generic__data__reader_a91573d9599b503a6bdf2939e69659e8b}{lbann\+:\+:generic\+\_\+data\+\_\+reader\+:\+:set\+\_\+num\+\_\+iterations\+\_\+per\+\_\+epoch} (int num\+\_\+iterations\+\_\+per\+\_\+epoch)]B\+VE F\+I\+X\+ME merge this with alternate approach  
\item[\label{todo__todo000020}%
\Hypertarget{todo__todo000020}%
Member \hyperlink{classlbann_1_1generic__input__layer_ad0b8ea79bc508bd227e08124359531c8}{lbann\+:\+:generic\+\_\+input\+\_\+layer\+:\+:fp\+\_\+setup\+\_\+data} (int mini\+\_\+batch\+\_\+size) override]This functionality should probably be moved elsewhere  
\item[\label{todo__todo000023}%
\Hypertarget{todo__todo000023}%
Member \hyperlink{classlbann_1_1generic__target__layer_a57a60f5a28c9fb78d5151801123d4dba}{lbann\+:\+:generic\+\_\+target\+\_\+layer\+:\+:fp\+\_\+compute} () override]should this distribute the entire matrix even if there is only a partial mini-\/batch  
\item[\label{todo__todo000025}%
\Hypertarget{todo__todo000025}%
Member \hyperlink{classlbann_1_1generic__target__layer_a2d9f6ac689171acf0caceed3ed4f7ef9}{lbann\+:\+:generic\+\_\+target\+\_\+layer\+:\+:load\+From\+Checkpoint} (int fd, const char $\ast$filename, size\+\_\+t $\ast$bytes) override]should probably save m\+\_\+shared\+\_\+data\+\_\+reader  
\item[\label{todo__todo000022}%
\Hypertarget{todo__todo000022}%
Member \hyperlink{classlbann_1_1generic__target__layer_a7c15e3fe4f1fd7f0ccdbc4c3ed8c793e}{lbann\+:\+:generic\+\_\+target\+\_\+layer\+:\+:operator=} (const \hyperlink{classlbann_1_1generic__target__layer}{generic\+\_\+target\+\_\+layer} \&other)]Should this be a shallow copy?  
\item[\label{todo__todo000024}%
\Hypertarget{todo__todo000024}%
Member \hyperlink{classlbann_1_1generic__target__layer_aff8b79ff0392bd78c44a5a4f6b6ef549}{lbann\+:\+:generic\+\_\+target\+\_\+layer\+:\+:save\+To\+Checkpoint} (int fd, const char $\ast$filename, size\+\_\+t $\ast$bytes) const override]should probably save m\+\_\+shared\+\_\+data\+\_\+reader  
\item[\label{todo__todo000031}%
\Hypertarget{todo__todo000031}%
Member \hyperlink{namespacelbann_a8987701a637ff0e678114aa77e9c4d40}{lbann\+:\+:init\+\_\+data\+\_\+seq\+\_\+random} (int seed)]Support saving/restoring the generator\textquotesingle{}s state. This is directly supported via the $>$$>$ and $<$$<$ operators on the generator (reading/writing from/to a stream).  
\item[\label{todo__todo000030}%
\Hypertarget{todo__todo000030}%
Member \hyperlink{namespacelbann_acef152f20e422b3aea1a3c1691a533ac}{lbann\+:\+:init\+\_\+random} (int seed, \hyperlink{classlbann_1_1lbann__comm}{lbann\+\_\+comm} $\ast$comm)]Support saving/restoring the generator\textquotesingle{}s state. This is directly supported via the $>$$>$ and $<$$<$ operators on the generator (reading/writing from/to a stream).  
\item[\label{todo__todo000021}%
\Hypertarget{todo__todo000021}%
Member \hyperlink{classlbann_1_1input__layer_aad8b042899d86f5b7904d9d2653b5181}{lbann\+:\+:input\+\_\+layer$<$ T\+\_\+io\+\_\+buffer, T\+\_\+layout $>$\+:\+:input\+\_\+layer} (\hyperlink{classlbann_1_1lbann__comm}{lbann\+\_\+comm} $\ast$comm, int num\+\_\+parallel\+\_\+readers, std\+::map$<$ execution\+\_\+mode, generic\+\_\+data\+\_\+reader $\ast$$>$ data\+\_\+readers, bool data\+\_\+set\+\_\+spans\+\_\+models=true, bool for\+\_\+regression=false)]make the map and vector references  
\item[\label{todo__todo000001}%
\Hypertarget{todo__todo000001}%
Member \hyperlink{classlbann_1_1lbann__callback__debug__io_aa3d2a6fb4d7375c05ece0058224ea792}{lbann\+:\+:lbann\+\_\+callback\+\_\+debug\+\_\+io\+:\+:on\+\_\+epoch\+\_\+begin} (model $\ast$m) override]The use of execution\+\_\+mode invalid needs to be reconsidered  
\item[\label{todo__todo000002}%
\Hypertarget{todo__todo000002}%
Member \hyperlink{classlbann_1_1lbann__callback__ltfb_a7548166d170eda00e4e0cba6626a1a78}{lbann\+:\+:lbann\+\_\+callback\+\_\+ltfb\+:\+:setup} (model $\ast$m) override]Support L\+T\+FB with different models  
\item[\label{todo__todo000029}%
\Hypertarget{todo__todo000029}%
Member \hyperlink{classlbann_1_1lbann__quantizer_a22b898932caed41ccf24abcb67c00ba1}{lbann\+:\+:lbann\+\_\+quantizer\+:\+:get\+\_\+adaptive\+\_\+quantization\+\_\+copy\+\_\+threads} (El\+::\+Int width)]Make this configurable at compile time.  
\item[\label{todo__todo000028}%
\Hypertarget{todo__todo000028}%
Member \hyperlink{classlbann_1_1lbann__quantizer_aaa0c20f755437130172c40ca8e95bc3f}{lbann\+:\+:lbann\+\_\+quantizer\+:\+:get\+\_\+adaptive\+\_\+quantization\+\_\+threads} (El\+::\+Int width)]Make this configurable at compile time.  
\item[\label{todo__todo000026}%
\Hypertarget{todo__todo000026}%
Member \hyperlink{classlbann_1_1model_ad0cdcba177434b52dc9c4a97be183a92}{lbann\+:\+:model\+:\+:get\+\_\+cur\+\_\+step} () const]This should be renamed to get\+\_\+cur\+\_\+training step and replaced with one that returns the current based on execution mode  
\item[\label{todo__todo000004}%
\Hypertarget{todo__todo000004}%
Member \hyperlink{namespacelbann_1_1proto_a00597c8b7450c389847980cf6934a619}{lbann\+:\+:proto\+:\+:construct\+\_\+callback} (\hyperlink{classlbann_1_1lbann__comm}{lbann\+\_\+comm} $\ast$comm, const lbann\+\_\+data\+::\+Callback \&proto\+\_\+cb, std\+::map$<$ execution\+\_\+mode, generic\+\_\+data\+\_\+reader $\ast$$>$ \&data\+\_\+readers, std\+::vector$<$ Layer $\ast$$>$ layer\+\_\+list, std\+::vector$<$ weights $\ast$$>$ weights\+\_\+list, \hyperlink{classlbann_1_1lbann__summary}{lbann\+\_\+summary} $\ast$summarizer)]

Initialize weights 

Initialize weights 

Initialize weights  
\item[\label{todo__todo000006}%
\Hypertarget{todo__todo000006}%
Member \hyperlink{namespacelbann_1_1proto_a7e4b0a66836712b1713ae4a121453cde}{lbann\+:\+:proto\+:\+:construct\+\_\+layer} (\hyperlink{classlbann_1_1lbann__comm}{lbann\+\_\+comm} $\ast$comm, std\+::map$<$ execution\+\_\+mode, generic\+\_\+data\+\_\+reader $\ast$$>$ \&data\+\_\+readers, int num\+\_\+parallel\+\_\+readers, \hyperlink{classlbann_1_1cudnn_1_1cudnn__manager}{cudnn\+::cudnn\+\_\+manager} $\ast$cudnn, const lbann\+\_\+data\+::\+Layer \&proto\+\_\+layer)]Support for G\+PU model-\/parallel layers  
\item[\label{todo__todo000010}%
\Hypertarget{todo__todo000010}%
Member \hyperlink{namespacelbann_a9b1fd2f864f421aa0bd9f8582ad87c14}{lbann\+:\+:rowwise\+\_\+mean\+\_\+and\+\_\+stdev} (const Abs\+Dist\+Mat \&data, Abs\+Dist\+Mat \&means, Abs\+Dist\+Mat \&stdevs)]Numerically stable implementation  
\item[\label{todo__todo000009}%
\Hypertarget{todo__todo000009}%
Member \hyperlink{namespacelbann_a6b342b3e5b3fbb08b97b6d90aa68d121}{lbann\+:\+:rowwise\+\_\+sums\+\_\+and\+\_\+sqsums} (const Abs\+Dist\+Mat \&data, Abs\+Dist\+Mat \&sums, Abs\+Dist\+Mat \&sqsums)]Numerically stable implementation  
\item[\label{todo__todo000027}%
\Hypertarget{todo__todo000027}%
Member \hyperlink{classlbann_1_1sequential__model_aa405c653dae867e862475e13b9df1db0}{lbann\+:\+:sequential\+\_\+model\+:\+:load\+\_\+from\+\_\+checkpoint} (int fd, const char $\ast$filename, size\+\_\+t $\ast$bytes)]This is old and likely broken  
\item[\label{todo__todo000003}%
\Hypertarget{todo__todo000003}%
Member \hyperlink{classlbann_1_1siamese__model_a7ff41cffb060500605124959f1a2a6cf}{lbann\+:\+:siamese\+\_\+model\+:\+:setup\+\_\+layer\+\_\+topology} () override]Handle case where heads have already been initialized.  
\item[\label{todo__todo000011}%
\Hypertarget{todo__todo000011}%
Member \hyperlink{classlbann_1_1weights_a1a2631987f38d32a90fbee61053a04cc}{lbann\+:\+:weights\+:\+:write\+\_\+proto} (lbann\+\_\+data\+::\+Weights\+Data $\ast$proto) const]What if weights are on G\+PU? 

What if world master is not process 0? 

Open\+MP parallelization 

Our matrices are column-\/major while Numpy expects row-\/major matrices. This row-\/wise iteration is fine for matrices and column vectors, but it can mess up the order of the weights if a high-\/dimensional tensor is represented as a matrix. This is what we need for quantization on convolution kernel weights. 
\end{DoxyRefList}