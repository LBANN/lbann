\hypertarget{classlbann_1_1lbann__callback__gradient__check}{}\section{lbann\+:\+:lbann\+\_\+callback\+\_\+gradient\+\_\+check Class Reference}
\label{classlbann_1_1lbann__callback__gradient__check}\index{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}}


{\ttfamily \#include $<$callback\+\_\+gradient\+\_\+check.\+hpp$>$}



Inheritance diagram for lbann\+:\+:lbann\+\_\+callback\+\_\+gradient\+\_\+check\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=192pt]{classlbann_1_1lbann__callback__gradient__check__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for lbann\+:\+:lbann\+\_\+callback\+\_\+gradient\+\_\+check\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=207pt]{classlbann_1_1lbann__callback__gradient__check__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\hyperlink{classlbann_1_1lbann__callback__gradient__check_ae198159c613bb05e00f49b824a61afbb}{lbann\+\_\+callback\+\_\+gradient\+\_\+check} (Data\+Type step\+\_\+size=Data\+Type(0), bool verbose=false, bool fail\+\_\+on\+\_\+error=false)
\item 
\hyperlink{classlbann_1_1lbann__callback__gradient__check_accd5a7f087c5bf782f17b428cfb75bdb}{lbann\+\_\+callback\+\_\+gradient\+\_\+check} (const \hyperlink{classlbann_1_1lbann__callback__gradient__check}{lbann\+\_\+callback\+\_\+gradient\+\_\+check} \&)=default
\item 
\hyperlink{classlbann_1_1lbann__callback__gradient__check}{lbann\+\_\+callback\+\_\+gradient\+\_\+check} \& \hyperlink{classlbann_1_1lbann__callback__gradient__check_a937cc9192005451b8e059b935533cecc}{operator=} (const \hyperlink{classlbann_1_1lbann__callback__gradient__check}{lbann\+\_\+callback\+\_\+gradient\+\_\+check} \&)=default
\item 
\hyperlink{classlbann_1_1lbann__callback__gradient__check}{lbann\+\_\+callback\+\_\+gradient\+\_\+check} $\ast$ \hyperlink{classlbann_1_1lbann__callback__gradient__check_a3cf248258a45ee721907864d62a17355}{copy} () const override
\item 
void \hyperlink{classlbann_1_1lbann__callback__gradient__check_ab62102d5ab30330386514161b9ee6586}{on\+\_\+test\+\_\+begin} (\hyperlink{classlbann_1_1model}{model} $\ast$m) override
\item 
std\+::string \hyperlink{classlbann_1_1lbann__callback__gradient__check_ad068bba7a10853f38cc9f58867dc468b}{name} () const override
\item 
Data\+Type \hyperlink{classlbann_1_1lbann__callback__gradient__check_a54ba40dd3b381d5c889d77edeffa37f9}{compute\+\_\+objective\+\_\+function} (\hyperlink{classlbann_1_1model}{model} $\ast$m)
\end{DoxyCompactItemize}
\subsection*{Private Attributes}
\begin{DoxyCompactItemize}
\item 
Data\+Type \hyperlink{classlbann_1_1lbann__callback__gradient__check_ab324dbfc7d21b69f135d33ee8290c4b2}{m\+\_\+step\+\_\+size}
\item 
bool \hyperlink{classlbann_1_1lbann__callback__gradient__check_a9a8669004ccfc3b76963ba13252600d3}{m\+\_\+verbose}
\item 
bool \hyperlink{classlbann_1_1lbann__callback__gradient__check_ac05a23972812866458fff241de0bb324}{m\+\_\+fail\+\_\+on\+\_\+error}
\end{DoxyCompactItemize}
\subsection*{Additional Inherited Members}


\subsection{Detailed Description}
Callback hooks for gradient check. 

Definition at line 37 of file callback\+\_\+gradient\+\_\+check.\+hpp.



\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classlbann_1_1lbann__callback__gradient__check_ae198159c613bb05e00f49b824a61afbb}\label{classlbann_1_1lbann__callback__gradient__check_ae198159c613bb05e00f49b824a61afbb}} 
\index{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}!lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+\_\+callback\+\_\+gradient\+\_\+check}}
\index{lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+\_\+callback\+\_\+gradient\+\_\+check}!lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}}
\subsubsection{\texorpdfstring{lbann\+\_\+callback\+\_\+gradient\+\_\+check()}{lbann\_callback\_gradient\_check()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check (\begin{DoxyParamCaption}\item[{Data\+Type}]{step\+\_\+size = {\ttfamily DataType(0)},  }\item[{bool}]{verbose = {\ttfamily false},  }\item[{bool}]{fail\+\_\+on\+\_\+error = {\ttfamily false} }\end{DoxyParamCaption})}

Constructor. 
\begin{DoxyParams}{Parameters}
{\em step\+\_\+size} & Step size for numerical differentiation. \\
\hline
{\em verbose} & Whether to print results for each parameter. \\
\hline
\end{DoxyParams}


Definition at line 33 of file callback\+\_\+gradient\+\_\+check.\+cpp.


\begin{DoxyCode}
36   : \hyperlink{classlbann_1_1lbann__callback__gradient__check_ab324dbfc7d21b69f135d33ee8290c4b2}{m\_step\_size}(step\_size),
37     \hyperlink{classlbann_1_1lbann__callback__gradient__check_a9a8669004ccfc3b76963ba13252600d3}{m\_verbose}(verbose),
38     \hyperlink{classlbann_1_1lbann__callback__gradient__check_ac05a23972812866458fff241de0bb324}{m\_fail\_on\_error}(fail\_on\_error) \{\}
\end{DoxyCode}
Here is the caller graph for this function\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classlbann_1_1lbann__callback__gradient__check_ae198159c613bb05e00f49b824a61afbb_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{classlbann_1_1lbann__callback__gradient__check_accd5a7f087c5bf782f17b428cfb75bdb}\label{classlbann_1_1lbann__callback__gradient__check_accd5a7f087c5bf782f17b428cfb75bdb}} 
\index{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}!lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+\_\+callback\+\_\+gradient\+\_\+check}}
\index{lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+\_\+callback\+\_\+gradient\+\_\+check}!lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}}
\subsubsection{\texorpdfstring{lbann\+\_\+callback\+\_\+gradient\+\_\+check()}{lbann\_callback\_gradient\_check()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check (\begin{DoxyParamCaption}\item[{const \hyperlink{classlbann_1_1lbann__callback__gradient__check}{lbann\+\_\+callback\+\_\+gradient\+\_\+check} \&}]{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [default]}}



\subsection{Member Function Documentation}
\mbox{\Hypertarget{classlbann_1_1lbann__callback__gradient__check_a54ba40dd3b381d5c889d77edeffa37f9}\label{classlbann_1_1lbann__callback__gradient__check_a54ba40dd3b381d5c889d77edeffa37f9}} 
\index{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}!compute\+\_\+objective\+\_\+function@{compute\+\_\+objective\+\_\+function}}
\index{compute\+\_\+objective\+\_\+function@{compute\+\_\+objective\+\_\+function}!lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}}
\subsubsection{\texorpdfstring{compute\+\_\+objective\+\_\+function()}{compute\_objective\_function()}}
{\footnotesize\ttfamily Data\+Type lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check\+::compute\+\_\+objective\+\_\+function (\begin{DoxyParamCaption}\item[{\hyperlink{classlbann_1_1model}{model} $\ast$}]{m }\end{DoxyParamCaption})}

Compute objective function value. It is assumed that input data has already been loaded into the activations of the first layer. 

Definition at line 182 of file callback\+\_\+gradient\+\_\+check.\+cpp.


\begin{DoxyCode}
182                                                                            \{
183   \textcolor{keyword}{const} std::vector<Layer*>& layers = m->get\_layers();
184   objective\_function* obj\_fn = m->get\_objective\_function();
185   \textcolor{keywordflow}{for} (\textcolor{keywordtype}{size\_t} l = 1; l < layers.size(); l++) \{
186     layers[l]->forward\_prop();
187   \}
188   obj\_fn->start\_evaluation(m->get\_execution\_mode(),
189                            m->get\_current\_mini\_batch\_size());
190   \textcolor{keywordflow}{return} obj\_fn->finish\_evaluation(m->get\_execution\_mode(),
191                                    m->get\_current\_mini\_batch\_size());
192 \}
\end{DoxyCode}
Here is the call graph for this function\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classlbann_1_1lbann__callback__gradient__check_a54ba40dd3b381d5c889d77edeffa37f9_cgraph}
\end{center}
\end{figure}
Here is the caller graph for this function\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classlbann_1_1lbann__callback__gradient__check_a54ba40dd3b381d5c889d77edeffa37f9_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{classlbann_1_1lbann__callback__gradient__check_a3cf248258a45ee721907864d62a17355}\label{classlbann_1_1lbann__callback__gradient__check_a3cf248258a45ee721907864d62a17355}} 
\index{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}!copy@{copy}}
\index{copy@{copy}!lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}}
\subsubsection{\texorpdfstring{copy()}{copy()}}
{\footnotesize\ttfamily \hyperlink{classlbann_1_1lbann__callback__gradient__check}{lbann\+\_\+callback\+\_\+gradient\+\_\+check}$\ast$ lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check\+::copy (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [override]}, {\ttfamily [virtual]}}



Implements \hyperlink{classlbann_1_1lbann__callback_a9f545d1269a8c7af335625d049691f26}{lbann\+::lbann\+\_\+callback}.



Definition at line 50 of file callback\+\_\+gradient\+\_\+check.\+hpp.


\begin{DoxyCode}
50 \{ \textcolor{keywordflow}{return} \textcolor{keyword}{new} \hyperlink{classlbann_1_1lbann__callback__gradient__check_ae198159c613bb05e00f49b824a61afbb}{lbann\_callback\_gradient\_check}(*\textcolor{keyword}{this}); \}
\end{DoxyCode}
Here is the call graph for this function\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classlbann_1_1lbann__callback__gradient__check_a3cf248258a45ee721907864d62a17355_cgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{classlbann_1_1lbann__callback__gradient__check_ad068bba7a10853f38cc9f58867dc468b}\label{classlbann_1_1lbann__callback__gradient__check_ad068bba7a10853f38cc9f58867dc468b}} 
\index{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}!name@{name}}
\index{name@{name}!lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}}
\subsubsection{\texorpdfstring{name()}{name()}}
{\footnotesize\ttfamily std\+::string lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check\+::name (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [override]}, {\ttfamily [virtual]}}

Return this callback\textquotesingle{}s name. 

Implements \hyperlink{classlbann_1_1lbann__callback_a7522c7a14f1d6a1ea762cc2d7248eb3a}{lbann\+::lbann\+\_\+callback}.



Definition at line 52 of file callback\+\_\+gradient\+\_\+check.\+hpp.


\begin{DoxyCode}
52 \{ \textcolor{keywordflow}{return} \textcolor{stringliteral}{"gradient check"}; \}
\end{DoxyCode}
Here is the call graph for this function\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classlbann_1_1lbann__callback__gradient__check_ad068bba7a10853f38cc9f58867dc468b_cgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{classlbann_1_1lbann__callback__gradient__check_ab62102d5ab30330386514161b9ee6586}\label{classlbann_1_1lbann__callback__gradient__check_ab62102d5ab30330386514161b9ee6586}} 
\index{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}!on\+\_\+test\+\_\+begin@{on\+\_\+test\+\_\+begin}}
\index{on\+\_\+test\+\_\+begin@{on\+\_\+test\+\_\+begin}!lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}}
\subsubsection{\texorpdfstring{on\+\_\+test\+\_\+begin()}{on\_test\_begin()}}
{\footnotesize\ttfamily void lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check\+::on\+\_\+test\+\_\+begin (\begin{DoxyParamCaption}\item[{\hyperlink{classlbann_1_1model}{model} $\ast$}]{m }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [override]}, {\ttfamily [virtual]}}

Called at the beginning of testing. 

Reimplemented from \hyperlink{classlbann_1_1lbann__callback_a716bff45bdc5a88eed09c2231f5bc93a}{lbann\+::lbann\+\_\+callback}.



Definition at line 40 of file callback\+\_\+gradient\+\_\+check.\+cpp.


\begin{DoxyCode}
40                                                           \{
41 
42   \textcolor{comment}{// Get model members}
43   lbann\_comm *\hyperlink{file__io_8cpp_ab048c6f9fcbcfaa57ce68b00263dbebe}{comm} = m->get\_comm();
44   \textcolor{keyword}{const} std::vector<Layer*>& layers = m->get\_layers();
45 
46   \textcolor{comment}{// Initialize network for testing}
47   \textcolor{keywordflow}{for} (\textcolor{keyword}{auto}&& w : m->get\_weights()) \{
48     \textcolor{keyword}{auto}&& opt = w->get\_optimizer();
49     \textcolor{keywordflow}{if} (opt != \textcolor{keyword}{nullptr}) \{ opt->clear\_gradient(); \}
50   \}
51   layers[0]->forward\_prop();
52 
53   \textcolor{comment}{// Compute objective function}
54   \textcolor{keyword}{const} DataType objective = \hyperlink{classlbann_1_1lbann__callback__gradient__check_a54ba40dd3b381d5c889d77edeffa37f9}{compute\_objective\_function}(m);
55 
56   \textcolor{comment}{// Choose finite difference step}
57   \textcolor{comment}{// Note: Consider a central difference scheme:}
58   \textcolor{comment}{//   f'(x) ~ ( - f(x+2h) + 8 f(x+h) - 8 f(x-h) + f(x-2h) ) / 12h}
59   \textcolor{comment}{// By Taylor's theorem, the truncation error is bounded by}
60   \textcolor{comment}{//   E\_trunc <= | f'''''(xi) | / 18 * h^4}
61   \textcolor{comment}{// Assuming f can be computed to a relative accuracy of epsilon,}
62   \textcolor{comment}{//   E\_fl <= epsilon * | f(chi) | / h}
63   \textcolor{comment}{// For simplicity, we assume f(chi) ~ f(x), and | f'''''(xi) | ~ 1.}
64   \textcolor{comment}{// If step size is not specified, then we choose h so that}
65   \textcolor{comment}{//   E\_fl <= sqrt(epsilon)}
66   \textcolor{keyword}{const} DataType epsilon = std::pow(std::numeric\_limits<DataType>::epsilon(), 0.9);
67   DataType step\_size = \hyperlink{classlbann_1_1lbann__callback__gradient__check_ab324dbfc7d21b69f135d33ee8290c4b2}{m\_step\_size};
68   \textcolor{keywordflow}{if} (\hyperlink{classlbann_1_1lbann__callback__gradient__check_ab324dbfc7d21b69f135d33ee8290c4b2}{m\_step\_size} <= DataType(0)) \{
69     step\_size = std::fabs(objective) * std::sqrt(epsilon);
70   \}
71   DataType expected\_error = (epsilon * objective / step\_size
72                              + std::pow(step\_size, 4) / 18);
73   expected\_error = std::pow(expected\_error, 0.9);
74 
75   \textcolor{comment}{// Compute gradients}
76   \textcolor{keywordflow}{for} (\textcolor{keyword}{auto}&& l : layers) \{
77     l->clear\_error\_signals(m->get\_current\_mini\_batch\_size());
78   \}
79   m->get\_objective\_function()->differentiate();
80   m->get\_objective\_function()->compute\_weight\_regularization();
81   \textcolor{keywordflow}{for} (\textcolor{keywordtype}{int} l = layers.size() - 1; l > 0; --l) \{
82     layers[l]->back\_prop();
83   \}
84 
85   \textcolor{comment}{// Print objective function value}
86   \textcolor{keywordflow}{if} (comm->am\_world\_master()) \{
87     std::cout << \textcolor{stringliteral}{"--------------------------------------------------------------------------------"} << 
      std::endl
88               << \textcolor{stringliteral}{"Gradient checking..."} << std::endl
89               << \textcolor{stringliteral}{"  Objective function value = "} << objective << std::endl
90               << \textcolor{stringliteral}{"  Step size                = "} << step\_size << std::endl
91               << \textcolor{stringliteral}{"  Expected gradient error  = "} << expected\_error << std::endl;
92   \}
93 
94   \textcolor{keywordflow}{for} (weights *w : m->get\_weights()) \{
95     \textcolor{keywordflow}{if} (w->get\_optimizer() == \textcolor{keyword}{nullptr}) \{
96       \textcolor{keywordflow}{continue};
97     \}
98     \textcolor{keywordflow}{if} (comm->am\_world\_master()) \{
99       std::cout << \textcolor{stringliteral}{"Checking "} << w->get\_name() << std::endl;
100     \}
101 
102     \textcolor{comment}{// Get weights matrix and gradient}
103     \textcolor{keyword}{const} \hyperlink{base_8hpp_a9a697a504ae84010e7439ffec862b470}{AbsDistMat}& weights\_matrix = w->get\_values();
104     \textcolor{keyword}{const} \hyperlink{base_8hpp_a9a697a504ae84010e7439ffec862b470}{AbsDistMat}& gradient = w->get\_optimizer()->get\_gradient();
105 
106     \textcolor{comment}{// Iterate through weights matrix entries}
107     \textcolor{keywordflow}{for} (El::Int col = 0; col < weights\_matrix.Width(); ++col) \{
108       \textcolor{keywordflow}{for} (El::Int row = 0; row < weights\_matrix.Height(); ++row) \{
109         \textcolor{keyword}{const} \textcolor{keywordtype}{bool} weight\_is\_local = weights\_matrix.IsLocal(row, col);
110         \textcolor{keyword}{const} El::Int local\_row = (weight\_is\_local ?
111                                    weights\_matrix.LocalRow(row) :
112                                    0);
113         \textcolor{keyword}{const} El::Int local\_col = (weight\_is\_local ?
114                                    weights\_matrix.LocalCol(col) :
115                                    0);
116         \textcolor{keyword}{const} DataType initial\_weight = (weight\_is\_local ?
117                                          weights\_matrix.GetLocal(local\_row,
118                                                                  local\_col) :
119                                          DataType(0));
120 
121         \textcolor{comment}{// Compute objective function values}
122         \textcolor{comment}{// Note: matrix entry is reset after computing objective}
123         \textcolor{comment}{// function values}
124         w->set\_value(initial\_weight + 2 * step\_size, row, col);
125         \textcolor{keyword}{const} DataType f\_2h = \hyperlink{classlbann_1_1lbann__callback__gradient__check_a54ba40dd3b381d5c889d77edeffa37f9}{compute\_objective\_function}(m);
126         w->set\_value(initial\_weight + step\_size, row, col);
127         \textcolor{keyword}{const} DataType f\_h = \hyperlink{classlbann_1_1lbann__callback__gradient__check_a54ba40dd3b381d5c889d77edeffa37f9}{compute\_objective\_function}(m);
128         w->set\_value(initial\_weight - step\_size, row, col);
129         \textcolor{keyword}{const} DataType f\_nh = \hyperlink{classlbann_1_1lbann__callback__gradient__check_a54ba40dd3b381d5c889d77edeffa37f9}{compute\_objective\_function}(m);
130         w->set\_value(initial\_weight - 2 * step\_size, row, col);
131         \textcolor{keyword}{const} DataType f\_n2h = \hyperlink{classlbann_1_1lbann__callback__gradient__check_a54ba40dd3b381d5c889d77edeffa37f9}{compute\_objective\_function}(m);
132         w->set\_value(initial\_weight, row, col);
133 
134         \textcolor{comment}{// Compute relative error in gradient.}
135         \textcolor{comment}{// Note: only weight owner participates}
136         \textcolor{keywordflow}{if} (weight\_is\_local && weights\_matrix.RedundantRank() == 0) \{
137           \textcolor{keyword}{const} DataType analytical\_gradient
138             = gradient.GetLocal(local\_row, local\_col);
139           \textcolor{keyword}{const} DataType numerical\_gradient
140             = (- f\_2h + 8 * f\_h - 8 * f\_nh + f\_n2h) / (12 * step\_size);
141           \textcolor{keyword}{const} DataType error = std::fabs(analytical\_gradient - numerical\_gradient);
142           \textcolor{keyword}{auto} relative\_error = DataType(0);
143           \textcolor{keywordflow}{if} (error != DataType(0)) \{
144             relative\_error = error / std::max(std::fabs(analytical\_gradient),
145                                               std::fabs(numerical\_gradient));
146           \}
147         
148           \textcolor{comment}{// Print warning if relative error is large}
149           \textcolor{keywordflow}{if} (error > expected\_error || std::isnan(error) || std::isinf(error)) \{
150             std::cout << \textcolor{stringliteral}{"  GRADIENT ERROR: "} << w->get\_name() << \textcolor{stringliteral}{", "}
151                       << \textcolor{stringliteral}{"entry ("} << row << \textcolor{stringliteral}{","} << col << \textcolor{stringliteral}{")"} << std::endl;
152             std::cout << \textcolor{stringliteral}{"    Weight              = "} << initial\_weight << std::endl
153                       << \textcolor{stringliteral}{"    Analytical gradient = "} << analytical\_gradient << std::endl
154                       << \textcolor{stringliteral}{"    Numerical gradient  = "} << numerical\_gradient << std::endl
155                       << \textcolor{stringliteral}{"    Error               = "} << error << std::endl
156                       << \textcolor{stringliteral}{"    Relative error      = "} << relative\_error << std::endl;
157             \textcolor{keywordflow}{if} (\hyperlink{classlbann_1_1lbann__callback__gradient__check_ac05a23972812866458fff241de0bb324}{m\_fail\_on\_error}) \{
158               \textcolor{keywordflow}{throw} lbann\_exception(\textcolor{stringliteral}{"callback\_gradient\_check: found large error in gradient"});
159             \}
160           \} \textcolor{keywordflow}{else} \textcolor{keywordflow}{if} (\hyperlink{classlbann_1_1lbann__callback__gradient__check_a9a8669004ccfc3b76963ba13252600d3}{m\_verbose}) \{
161             std::cout << \textcolor{stringliteral}{"  "} << w->get\_name() << \textcolor{stringliteral}{", "}
162                       << \textcolor{stringliteral}{"entry ("} << row << \textcolor{stringliteral}{","} << col << \textcolor{stringliteral}{")"} << std::endl;
163             std::cout << \textcolor{stringliteral}{"    Weight              = "} << initial\_weight << std::endl
164                       << \textcolor{stringliteral}{"    Analytical gradient = "} << analytical\_gradient << std::endl
165                       << \textcolor{stringliteral}{"    Numerical gradient  = "} << numerical\_gradient << std::endl
166                       << \textcolor{stringliteral}{"    Error               = "} << error << std::endl
167                       << \textcolor{stringliteral}{"    Relative error      = "} << relative\_error << std::endl;
168           \}
169         \}
170 
171       \}
172     \}
173 
174   \}
175 
176   \textcolor{keywordflow}{if} (comm->am\_world\_master()) \{
177     std::cout << \textcolor{stringliteral}{"--------------------------------------------------------------------------------"} << 
      std::endl;
178   \}
179 
180 \}
\end{DoxyCode}
Here is the call graph for this function\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classlbann_1_1lbann__callback__gradient__check_ab62102d5ab30330386514161b9ee6586_cgraph}
\end{center}
\end{figure}
Here is the caller graph for this function\+:\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classlbann_1_1lbann__callback__gradient__check_ab62102d5ab30330386514161b9ee6586_icgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{classlbann_1_1lbann__callback__gradient__check_a937cc9192005451b8e059b935533cecc}\label{classlbann_1_1lbann__callback__gradient__check_a937cc9192005451b8e059b935533cecc}} 
\index{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}!operator=@{operator=}}
\index{operator=@{operator=}!lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}}
\subsubsection{\texorpdfstring{operator=()}{operator=()}}
{\footnotesize\ttfamily \hyperlink{classlbann_1_1lbann__callback__gradient__check}{lbann\+\_\+callback\+\_\+gradient\+\_\+check}\& lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check\+::operator= (\begin{DoxyParamCaption}\item[{const \hyperlink{classlbann_1_1lbann__callback__gradient__check}{lbann\+\_\+callback\+\_\+gradient\+\_\+check} \&}]{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [default]}}



\subsection{Member Data Documentation}
\mbox{\Hypertarget{classlbann_1_1lbann__callback__gradient__check_ac05a23972812866458fff241de0bb324}\label{classlbann_1_1lbann__callback__gradient__check_ac05a23972812866458fff241de0bb324}} 
\index{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}!m\+\_\+fail\+\_\+on\+\_\+error@{m\+\_\+fail\+\_\+on\+\_\+error}}
\index{m\+\_\+fail\+\_\+on\+\_\+error@{m\+\_\+fail\+\_\+on\+\_\+error}!lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}}
\subsubsection{\texorpdfstring{m\+\_\+fail\+\_\+on\+\_\+error}{m\_fail\_on\_error}}
{\footnotesize\ttfamily bool lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check\+::m\+\_\+fail\+\_\+on\+\_\+error\hspace{0.3cm}{\ttfamily [private]}}

Whether to throw an exception for large gradient errors. 

Definition at line 66 of file callback\+\_\+gradient\+\_\+check.\+hpp.

\mbox{\Hypertarget{classlbann_1_1lbann__callback__gradient__check_ab324dbfc7d21b69f135d33ee8290c4b2}\label{classlbann_1_1lbann__callback__gradient__check_ab324dbfc7d21b69f135d33ee8290c4b2}} 
\index{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}!m\+\_\+step\+\_\+size@{m\+\_\+step\+\_\+size}}
\index{m\+\_\+step\+\_\+size@{m\+\_\+step\+\_\+size}!lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}}
\subsubsection{\texorpdfstring{m\+\_\+step\+\_\+size}{m\_step\_size}}
{\footnotesize\ttfamily Data\+Type lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check\+::m\+\_\+step\+\_\+size\hspace{0.3cm}{\ttfamily [private]}}

Step size for numerical differentiation. 

Definition at line 62 of file callback\+\_\+gradient\+\_\+check.\+hpp.

\mbox{\Hypertarget{classlbann_1_1lbann__callback__gradient__check_a9a8669004ccfc3b76963ba13252600d3}\label{classlbann_1_1lbann__callback__gradient__check_a9a8669004ccfc3b76963ba13252600d3}} 
\index{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}!m\+\_\+verbose@{m\+\_\+verbose}}
\index{m\+\_\+verbose@{m\+\_\+verbose}!lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check@{lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check}}
\subsubsection{\texorpdfstring{m\+\_\+verbose}{m\_verbose}}
{\footnotesize\ttfamily bool lbann\+::lbann\+\_\+callback\+\_\+gradient\+\_\+check\+::m\+\_\+verbose\hspace{0.3cm}{\ttfamily [private]}}

Whether to print results for each parameter. 

Definition at line 64 of file callback\+\_\+gradient\+\_\+check.\+hpp.



The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
/\+Users/mckinney27/doxy-\/testbed/lbann/include/lbann/callbacks/\hyperlink{callback__gradient__check_8hpp}{callback\+\_\+gradient\+\_\+check.\+hpp}\item 
/\+Users/mckinney27/doxy-\/testbed/lbann/src/callbacks/\hyperlink{callback__gradient__check_8cpp}{callback\+\_\+gradient\+\_\+check.\+cpp}\end{DoxyCompactItemize}
