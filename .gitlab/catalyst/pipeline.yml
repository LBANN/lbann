################################################################################
## Copyright (c) 2014-2022, Lawrence Livermore National Security, LLC.
## Produced at the Lawrence Livermore National Laboratory.
## Written by the LBANN Research Team (B. Van Essen, et al.) listed in
## the CONTRIBUTORS file. <lbann-dev@llnl.gov>
##
## LLNL-CODE-697807.
## All rights reserved.
##
## This file is part of LBANN: Livermore Big Artificial Neural Network
## Toolkit. For details, see http://software.llnl.gov/LBANN or
## https://github.com/LLNL/LBANN.
##
## Licensed under the Apache License, Version 2.0 (the "Licensee"); you
## may not use this file except in compliance with the License.  You may
## obtain a copy of the License at:
##
## http://www.apache.org/licenses/LICENSE-2.0
##
## Unless required by applicable law or agreed to in writing, software
## distributed under the License is distributed on an "AS IS" BASIS,
## WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
## implied. See the License for the specific language governing
## permissions and limitations under the license.
################################################################################

# This is the testing pipeline for the Catalyst cluster at LLNL. This
# cluster builds the LBANN applications and libraries using a single
# compiler toolchain and then runs a collection of tests. Testing
# output is in JUnit format and parsed by the pipeline for web
# viewing.

include:
  - .gitlab/common/common.yml

stages:
  - allocate
  - build
  - test
  - deallocate

# The purpose of this job is simply to allocate some nodes for the
# pipeline to utilize. The trick here is JOB_NAME. Later on, we will
# extract the job ID from the SLURM queue using this name. It will be
# unique to this pipeline and therefore shared across all jobs in this
# pipeline.
allocate lc resources:
  stage: allocate
  extends:
    - .catalyst common
    - .lbann-base-vars
  variables:
    GIT_STRATEGY: none
  script:
    - echo "== ACQUIRING SLURM RESOURCES =="
    - echo "${WITH_WEEKLY:+Running with --weekly}"
    - export TEST_TIME=$([[ -n "${WITH_WEEKLY}" ]] && echo "120" || echo "90")
    - export LBANN_NNODES=$([[ -n "${WITH_WEEKLY}" ]] && echo "4" || echo "2")
    - salloc --exclusive -N ${LBANN_NNODES} -p pbatch -t ${TEST_TIME} --no-shell -J ${JOB_NAME}
  timeout: 6h

# This replaces "test_compiler.py". This has the advantage that it
# very explicitly approximates what a user would do to build LBANN.
#
# This job also establishes the Spack environment that we will
# use. We'll use the same environment for the whole pipeline. This
# should be fine as the test jobs will view the environment as
# "read-only".
build and install:
  extends:
    - .catalyst common
    - .lbann-base-vars
    - .lbann-artifacts
  stage: build
  script:
    - echo "== BUILDING LBANN =="
    - export JOB_ID=$(squeue -h -n "${JOB_NAME}" -o "%A")
    - !reference [.setup_spack, script]
    - srun --jobid=${JOB_ID} -N 1 -t 30 ./scripts/build_lbann.sh ${SPACK_DEPS_FLAG}
      -l ${SPACK_ENV_NAME} -j ${BUILD_TASKS} ${CLEAN_BUILD_FLAG}
      -p py-pip --ci-pip --
      +deterministic +vision +numpy +unit_tests ${SPACK_SPECS}
    - export TEST_TASKS_PER_NODE=4
    - export TEST_MPIBIND_FLAG="--mpibind=off"
    - export SPACK_ARCH=$(spack arch)
    - export SPACK_ARCH_TARGET=$(spack arch -t)
    - !reference [.setup_lbann, script]
    - .gitlab/common/run-catch-tests.sh

# The next two jobs effectively replace the rest of "run.sh".
#
# There is a bit of a hack going on here: instead of passing
# "--jobid=${JOB_ID}" to an srun command, we "export
# SLURM_JOB_ID=${JOB_ID}" into the environment prior to launching the
# test script. The reason for this is that the srun commands are
# buried deep inside the Python infrastructure and it would be
# nontrivial to push them all the way in (not so nontrivial that this
# wouldn't be worth doing, but nontrivial enough that it should be its
# own PR).
#
# This appears to be working with one main side effect: as written,
# the integration tests and the unit tests will interfere with each
# other. It's not clear if they are interleaving or overlapping. This
# happens because the two jobs in the test stage will run
# concurrently. We can change this if it's shown to be a problem.
unit tests:
  extends:
    - .catalyst common
    - .lbann-base-vars
    - .uses spack environment
  stage: test
  dependencies:
    - build and install
  script:
    - echo "== RUNNING PYTHON-BASED UNIT TESTS =="
    - echo "Testing $(which lbann)"
    - export OMP_NUM_THREADS=10
    - export SLURM_JOB_ID=$(squeue -h -n "${JOB_NAME}" -o "%A")
    - cd ci_test/unit_tests
    - lbann_pfe.sh -m pytest -s -vv --durations=0 --junitxml=results.xml
  artifacts:
    when: always
    paths:
      - ci_test/unit_tests/results.xml
    reports:
      junit: ci_test/unit_tests/results.xml

integration tests:
  extends:
    - .catalyst common
    - .lbann-base-vars
    - .uses spack environment
  stage: test
  dependencies:
    - build and install
  script:
    - echo "== RUNNING PYTHON-BASED INTEGRATION TESTS =="
    - echo "Testing $(which lbann)"
    - export OMP_NUM_THREADS=10
    - export SLURM_JOB_ID=$(squeue -h -n "${JOB_NAME}" -o "%A")
    - cd ci_test/integration_tests
    - export WEEKLY_FLAG=${WITH_WEEKLY:+--weekly}
    - echo "python3 -m pytest -s -vv --durations=0 ${WEEKLY_FLAG} --junitxml=results.xml"
    - lbann_pfe.sh -m pytest -s -vv --durations=0 ${WEEKLY_FLAG} --junitxml=results.xml
  artifacts:
    when: always
    paths:
      - ci_test/integration_tests/results.xml
    reports:
      junit: ci_test/integration_tests/results.xml

# This is a dummy job that checks the output of the Catch2
# testing. This is one of the gotchas of GitLab: The Catch2 test
# executables are artifacts of the build procedure, but we don't save
# the entire build as artifacts (it would be very large and there's no
# need since the rest of the tests run on the installed targets (for
# better or worse)). For maximum clarity from the web interface, we
# write a file when the Catch tests fail but then return success from
# the script that runs them. This means that the build job will fail
# iff the build fails. This job will be marked as "failed" if any of
# the catch tests failed, and the pytest-based unit/integration tests
# will run any time the build succeeds.
check catch2 tests:
  extends:
    - .catalyst common
    - .lbann-base-vars
  stage: test
  dependencies:
    - build and install
  script:
    - ([[ $(find ${RESULTS_DIR} -name "catch-tests-failed.txt" | wc -l) -eq 0 ]])
  artifacts:
    reports:
      junit: ${RESULTS_DIR}/*.xml

# Cleanup this pipeline's spack environment.
# Switching over to reusing Spack environments for each feature branch so don't remove them immediately
# Cleanup any build directories and spack environments older than 5 days since last use
remove spack environment:
  extends:
    - .catalyst common
    - .lbann-base-vars
    - .cleanup old spack environment
  stage: deallocate
  variables:
    GIT_STRATEGY: none
  when: always

# This frees the allocation we obtained in "allocate lc resources".
release allocation:
  stage: deallocate
  extends:
    - .catalyst common
    - .lbann-base-vars
  variables:
    GIT_STRATEGY: none
  when: always
  script:
    - echo "== RELEASING RESOURCES =="
    - export JOB_ID=$(squeue -h -n "${JOB_NAME}" -o "%A")
    - ([[ -n "${JOB_ID}" ]] && scancel ${JOB_ID})

# For simplicity, I have put the variables as well as the tags
# here. The variables could just be top-level in the file (perhaps the
# tags could be, too, but I'm not sure), but this makes extracting
# them to another file easier down the road.
.catalyst common:
  variables:
    # Just the obvious identifier. Which specific node doesn't matter.
    SYSTEM_NAME: catalyst
    SPACK_USER_CACHE_PATH: /g/g14/lbannusr/spack_repos/.spack_develop
#    SPACK_REPO: spack_repos/spack_${SYSTEM_NAME}.git
    SPACK_REPO: spack_repos/spack_develop.git

    # These are system-specific specs that should be forwarded to the
    # build script
    SPACK_SPECS: "+onednn +half +fft"

  tags:
    - catalyst
    - shell
